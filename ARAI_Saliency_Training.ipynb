{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7531547",
   "metadata": {},
   "source": [
    "# üöÄ ARAI Saliency Model Training on Google Colab\n",
    "\n",
    "This notebook trains a U-Net saliency prediction model for the ARAI system.\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:**\n",
    "- Synthetic data: 30 minutes\n",
    "- Full SALICON: 2-4 hours\n",
    "\n",
    "**üìã Before Starting:**\n",
    "1. Click **Runtime ‚Üí Change runtime type**\n",
    "2. Select **GPU** as Hardware accelerator\n",
    "3. Click **Save**\n",
    "4. Run cells in order\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27400e0a",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: Check GPU and Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e179375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected!\")\n",
    "    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828eec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for saving models\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/ARAI/models', exist_ok=True)\n",
    "os.makedirs('/content/drive/MyDrive/ARAI/training_logs', exist_ok=True)\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive mounted successfully!\")\n",
    "print(\"üìÅ Models will be saved to: /content/drive/MyDrive/ARAI/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704d5fa",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone ARAI repository\n",
    "!git clone https://github.com/kavishaniy/ARAI-System.git /content/arai\n",
    "%cd /content/arai/backend\n",
    "\n",
    "print(\"‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (most are pre-installed in Colab)\n",
    "!pip install -q pillow scipy tqdm matplotlib scikit-image\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47edf91",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Choose Training Option\n",
    "\n",
    "### Option A: Quick Test with Synthetic Data (30 minutes) ‚ö°\n",
    "Run this cell for a quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset for quick testing\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('/content/synthetic_data/images', exist_ok=True)\n",
    "os.makedirs('/content/synthetic_data/maps', exist_ok=True)\n",
    "\n",
    "print(\"Creating 200 synthetic training samples...\")\n",
    "for i in tqdm(range(200)):\n",
    "    # Create UI-like image\n",
    "    img = np.random.randint(200, 255, (256, 256, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add UI elements (header, buttons, text areas)\n",
    "    cv2.rectangle(img, (20, 20), (236, 60), (66, 133, 244), -1)  # Header\n",
    "    cv2.putText(img, 'Title', (80, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    cv2.rectangle(img, (20, 80), (236, 180), (52, 168, 83), 3)  # CTA Button\n",
    "    cv2.putText(img, 'Click Me', (70, 135), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "    cv2.rectangle(img, (20, 190), (236, 240), (200, 200, 200), 1)  # Text box\n",
    "    \n",
    "    # Generate saliency map\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Add center bias (humans look at center more)\n",
    "    y, x = np.ogrid[:256, :256]\n",
    "    center_bias = np.exp(-((x - 128)**2 + (y - 128)**2) / (2 * 80**2))\n",
    "    \n",
    "    # Combine edge detection and center bias\n",
    "    saliency = (edges / 255.0 * 0.6 + center_bias * 0.4) * 255\n",
    "    saliency = saliency.astype(np.uint8)\n",
    "    \n",
    "    # Save\n",
    "    Image.fromarray(img).save(f'/content/synthetic_data/images/img_{i:04d}.jpg')\n",
    "    Image.fromarray(saliency).save(f'/content/synthetic_data/maps/map_{i:04d}.png')\n",
    "\n",
    "print(f\"\\n‚úÖ Created 200 synthetic training samples!\")\n",
    "print(\"üìÅ Location: /content/synthetic_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00866b2",
   "metadata": {},
   "source": [
    "### Option B: Download SALICON Dataset (for production) üéØ\n",
    "\n",
    "**Note:** This downloads ~2.5GB of data and takes 30-60 minutes.\n",
    "\n",
    "Skip this if you're using synthetic data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SALICON dataset\n",
    "!pip install -q gdown\n",
    "import gdown\n",
    "\n",
    "os.makedirs('/content/salicon/images', exist_ok=True)\n",
    "os.makedirs('/content/salicon/maps', exist_ok=True)\n",
    "\n",
    "print(\"Downloading SALICON dataset...\")\n",
    "print(\"This may take 30-60 minutes for ~2.5GB of data\\n\")\n",
    "\n",
    "# SALICON Training Images (2GB)\n",
    "print(\"1/2 Downloading training images...\")\n",
    "gdown.download(\n",
    "    'https://drive.google.com/uc?id=1g8j-hTT2exMGdiN84XDHPJJgDXq8YCDH',\n",
    "    '/content/salicon_images.zip',\n",
    "    quiet=False\n",
    ")\n",
    "\n",
    "# SALICON Training Maps (500MB)\n",
    "print(\"\\n2/2 Downloading saliency maps...\")\n",
    "gdown.download(\n",
    "    'https://drive.google.com/uc?id=1jHbhwlMXXFvvLM0dAb0qC2vvXBkF8ZdL',\n",
    "    '/content/salicon_maps.zip',\n",
    "    quiet=False\n",
    ")\n",
    "\n",
    "# Extract files\n",
    "print(\"\\nExtracting files...\")\n",
    "!unzip -q /content/salicon_images.zip -d /content/salicon/images/\n",
    "!unzip -q /content/salicon_maps.zip -d /content/salicon/maps/\n",
    "\n",
    "print(\"\\n‚úÖ SALICON dataset ready!\")\n",
    "print(f\"   Images: {len(os.listdir('/content/salicon/images'))}\")\n",
    "print(f\"   Maps: {len(os.listdir('/content/salicon/maps'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3bdb2",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Train the Model üéì\n",
    "\n",
    "Choose one of the training cells below based on your dataset choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with SYNTHETIC DATA (quick test - 30 minutes)\n",
    "%cd /content/arai/backend/training\n",
    "\n",
    "!python train_saliency.py \\\n",
    "    --image_dir /content/synthetic_data/images \\\n",
    "    --saliency_dir /content/synthetic_data/maps \\\n",
    "    --batch_size 16 \\\n",
    "    --num_epochs 20 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --save_dir /content/drive/MyDrive/ARAI/models \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "print(\"üìÅ Model saved to: /content/drive/MyDrive/ARAI/models/saliency_model.pth\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca116247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with SALICON DATASET (production - 2-4 hours)\n",
    "%cd /content/arai/backend/training\n",
    "\n",
    "!python train_saliency.py \\\n",
    "    --image_dir /content/salicon/images \\\n",
    "    --saliency_dir /content/salicon/maps \\\n",
    "    --batch_size 16 \\\n",
    "    --num_epochs 50 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --save_dir /content/drive/MyDrive/ARAI/models \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "print(\"üìÅ Model saved to: /content/drive/MyDrive/ARAI/models/saliency_model.pth\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce5254",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Download Trained Model üì•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model to your computer\n",
    "from google.colab import files\n",
    "\n",
    "# Copy from Drive to Colab workspace (for faster download)\n",
    "!cp /content/drive/MyDrive/ARAI/models/saliency_model.pth /content/\n",
    "\n",
    "# Check file size\n",
    "import os\n",
    "size_mb = os.path.getsize('/content/saliency_model.pth') / 1e6\n",
    "print(f\"Model size: {size_mb:.1f} MB\")\n",
    "\n",
    "# Download to your computer\n",
    "print(\"\\nDownloading model to your computer...\")\n",
    "files.download('/content/saliency_model.pth')\n",
    "\n",
    "print(\"\\n‚úÖ Download complete!\")\n",
    "print(\"\\nüìã Next steps:\")\n",
    "print(\"   1. Move the downloaded file to: backend/models/saliency_model.pth\")\n",
    "print(\"   2. Restart your backend server\")\n",
    "print(\"   3. The model will be automatically detected and used!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db336ca2",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ View Training Results üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a79a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "curves_path = '/content/drive/MyDrive/ARAI/models/training_curves.png'\n",
    "\n",
    "if os.path.exists(curves_path):\n",
    "    display(IPImage(filename=curves_path))\n",
    "    print(\"\\n‚úÖ Training curves displayed above\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training curves not found. Did training complete?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59657fae",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Test the Model (Optional) üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model on a sample image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append('/content/arai/backend')\n",
    "from app.ai_modules.comprehensive_attention_analyzer import SaliencyModel\n",
    "from training.dataset import SaliencyDataset\n",
    "\n",
    "# Load model\n",
    "model = SaliencyModel()\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/ARAI/models/saliency_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Load a test image\n",
    "test_img_path = '/content/synthetic_data/images/img_0000.jpg'  # Change this path\n",
    "test_img = Image.open(test_img_path).convert('RGB')\n",
    "\n",
    "# Preprocess\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img_tensor = transform(test_img).unsqueeze(0)\n",
    "if torch.cuda.is_available():\n",
    "    img_tensor = img_tensor.cuda()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    saliency_pred = model(img_tensor)\n",
    "    saliency_pred = saliency_pred.squeeze().cpu().numpy()\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(test_img)\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(saliency_pred, cmap='hot')\n",
    "axes[1].set_title('Predicted Saliency Map')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Model test complete!\")\n",
    "print(f\"   Saliency range: [{saliency_pred.min():.3f}, {saliency_pred.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbb7e6",
   "metadata": {},
   "source": [
    "## üéâ Done!\n",
    "\n",
    "Your saliency model is trained and saved to Google Drive!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Download the model** (if you haven't already):\n",
    "   - Go to your Google Drive: `My Drive ‚Üí ARAI ‚Üí models`\n",
    "   - Download `saliency_model.pth` (~45MB)\n",
    "\n",
    "2. **Place in your project**:\n",
    "   ```bash\n",
    "   cd /Users/kavishani/Documents/FYP/arai-system/backend\n",
    "   mkdir -p models\n",
    "   # Move downloaded file here\n",
    "   ```\n",
    "\n",
    "3. **Restart your backend**:\n",
    "   ```bash\n",
    "   cd backend\n",
    "   python -m uvicorn app.main:app --reload\n",
    "   ```\n",
    "\n",
    "4. **Test in your web app**:\n",
    "   - Upload a design\n",
    "   - Check the saliency heatmap\n",
    "   - Compare with previous heuristic-based results\n",
    "\n",
    "**Expected Improvement:**\n",
    "- Accuracy: 70-80% ‚Üí 85-95%\n",
    "- More realistic attention patterns\n",
    "- Better prediction of user focus areas\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** Check `GOOGLE_COLAB_TRAINING_GUIDE.md` for troubleshooting!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
